{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5dL9I+s6/vJdG+5sJ81n0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivali57/salary_predict/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPAiZYKJOSOY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymNENDlZyXxy",
        "outputId": "5813422e-658d-411b-94fe-24175702b1d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SALARY PREDICTION WITH ENSEMBLE LEARNING\n",
            "============================================================\n",
            "============================================================\n",
            "STEP 1: LOADING AND PREPARING DATA\n",
            "============================================================\n",
            "Dataset loaded successfully! Shape: (375, 6)\n",
            "\n",
            "Original columns: ['Age', 'Gender', 'Education Level', 'Job Title', 'Years of Experience', 'Salary']\n",
            "\n",
            "Initial data info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 375 entries, 0 to 374\n",
            "Data columns (total 6 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Age                  373 non-null    float64\n",
            " 1   Gender               373 non-null    object \n",
            " 2   Education Level      373 non-null    object \n",
            " 3   Job Title            373 non-null    object \n",
            " 4   Years of Experience  373 non-null    float64\n",
            " 5   Salary               373 non-null    float64\n",
            "dtypes: float64(3), object(3)\n",
            "memory usage: 17.7+ KB\n",
            "None\n",
            "\n",
            "Missing values per column:\n",
            "Age                    2\n",
            "Gender                 2\n",
            "Education Level        2\n",
            "Job Title              2\n",
            "Years of Experience    2\n",
            "Salary                 2\n",
            "dtype: int64\n",
            "\n",
            "Handling missing values...\n",
            "Dropped rows with missing values. Rows removed: 2\n",
            "Final dataset shape after handling missing values: (373, 6)\n",
            "\n",
            "STEP 2: FEATURE SELECTION\n",
            "----------------------------------------\n",
            "‚úì Using feature: Age\n",
            "‚úì Using feature: Years of Experience\n",
            "‚úì Using feature: Gender\n",
            "‚úì Using feature: Education Level\n",
            "‚úì Using feature: Job Title\n",
            "\n",
            "Selected features: ['Age', 'Years of Experience', 'Gender', 'Education Level', 'Job Title']\n",
            "Target variable: Salary\n",
            "Feature matrix shape: (373, 5)\n",
            "Target vector shape: (373,)\n",
            "\n",
            "STEP 3: ENCODING CATEGORICAL FEATURES\n",
            "----------------------------------------\n",
            "Categorical columns: ['Gender', 'Education Level', 'Job Title']\n",
            "Numerical columns: ['Age', 'Years of Experience']\n",
            "\n",
            "STEP 4: SPLITTING THE DATA\n",
            "----------------------------------------\n",
            "Training set size: 298 samples\n",
            "Testing set size: 75 samples\n",
            "Training set percentage: 80.0%\n",
            "Testing set percentage: 20.0%\n",
            "\n",
            "STEP 5: CREATING ENSEMBLE MODELS\n",
            "----------------------------------------\n",
            "Created ensemble models:\n",
            "‚úì Random Forest\n",
            "‚úì Gradient Boosting\n",
            "‚úì Voting Regressor\n",
            "\n",
            "STEP 6: TRAINING AND EVALUATING MODELS\n",
            "============================================================\n",
            "\n",
            "Training Random Forest...\n",
            "Random Forest Results:\n",
            "  Training MAE: $6,731.89\n",
            "  Testing MAE:  $10,389.14\n",
            "  Training R¬≤:  0.9558\n",
            "  Testing R¬≤:   0.8927\n",
            "  Training RMSE: $10,082.33\n",
            "  Testing RMSE:  $16,036.66\n",
            "\n",
            "Training Gradient Boosting...\n",
            "Gradient Boosting Results:\n",
            "  Training MAE: $4,295.23\n",
            "  Testing MAE:  $10,474.57\n",
            "  Training R¬≤:  0.9833\n",
            "  Testing R¬≤:   0.8929\n",
            "  Training RMSE: $6,202.02\n",
            "  Testing RMSE:  $16,020.81\n",
            "\n",
            "Training Voting Regressor...\n",
            "Voting Regressor Results:\n",
            "  Training MAE: $5,263.52\n",
            "  Testing MAE:  $10,261.59\n",
            "  Training R¬≤:  0.9740\n",
            "  Testing R¬≤:   0.8948\n",
            "  Training RMSE: $7,730.15\n",
            "  Testing RMSE:  $15,880.92\n",
            "\n",
            "STEP 7: MODEL COMPARISON\n",
            "============================================================\n",
            "Model Performance Comparison:\n",
            "            Model   Test MAE Test R¬≤  Test RMSE\n",
            "    Random Forest $10,389.14  0.8927 $16,036.66\n",
            "Gradient Boosting $10,474.57  0.8929 $16,020.81\n",
            " Voting Regressor $10,261.59  0.8948 $15,880.92\n",
            "\n",
            "üèÜ Best Model: Voting Regressor\n",
            "   Test R¬≤ Score: 0.8948\n",
            "   Test MAE: $10,261.59\n",
            "\n",
            "STEP 8: SAVING THE MODEL\n",
            "----------------------------------------\n",
            "‚úì Model saved as: best_salary_model_voting_regressor.pkl\n",
            "‚úì Preprocessor saved as: best_salary_model_voting_regressor_preprocessor.pkl\n",
            "‚úì Feature info saved as: best_salary_model_voting_regressor_features.pkl\n",
            "\n",
            "üéâ SALARY PREDICTION MODEL TRAINING COMPLETED!\n",
            "Best model (Voting Regressor) has been saved and is ready for predictions.\n",
            "\n",
            "STEP 9: SAMPLE PREDICTION\n",
            "----------------------------------------\n",
            "Sample Input Data:\n",
            "  Age: 32.0\n",
            "  Years of Experience: 5.0\n",
            "  Gender: Male\n",
            "  Education Level: Bachelor's\n",
            "  Job Title: Software Engineer\n",
            "\n",
            "Predicted Salary: $58,884.19\n",
            "Actual Salary: $90,000.00\n",
            "Prediction Error: $31,115.81\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import joblib\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class SalaryPredictor:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.preprocessor = None\n",
        "        self.feature_columns = None\n",
        "\n",
        "    def load_and_prepare_data(self, csv_path=\"Salary Data.csv\"):\n",
        "        \"\"\"\n",
        "        Load and prepare the salary dataset for machine learning\n",
        "        \"\"\"\n",
        "        print(\"=\"*60)\n",
        "        print(\"STEP 1: LOADING AND PREPARING DATA\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Load the dataset\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"Dataset loaded successfully! Shape: {df.shape}\")\n",
        "        print(f\"\\nOriginal columns: {list(df.columns)}\")\n",
        "\n",
        "        # Display initial data info\n",
        "        print(f\"\\nInitial data info:\")\n",
        "        print(df.info())\n",
        "\n",
        "        # Check for missing values\n",
        "        print(f\"\\nMissing values per column:\")\n",
        "        missing_values = df.isnull().sum()\n",
        "        print(missing_values)\n",
        "\n",
        "        # Handle missing values\n",
        "        print(f\"\\nHandling missing values...\")\n",
        "        initial_rows = len(df)\n",
        "\n",
        "        # Option 1: Drop rows with missing values (if few missing values)\n",
        "        if missing_values.sum() < len(df) * 0.1:  # If less than 10% missing\n",
        "            df = df.dropna()\n",
        "            print(f\"Dropped rows with missing values. Rows removed: {initial_rows - len(df)}\")\n",
        "        else:\n",
        "            # Option 2: Fill missing values with median/mode\n",
        "            for col in df.columns:\n",
        "                if df[col].isnull().sum() > 0:\n",
        "                    if df[col].dtype in ['int64', 'float64']:\n",
        "                        df[col].fillna(df[col].median(), inplace=True)\n",
        "                        print(f\"Filled missing values in {col} with median\")\n",
        "                    else:\n",
        "                        df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "                        print(f\"Filled missing values in {col} with mode\")\n",
        "\n",
        "        print(f\"Final dataset shape after handling missing values: {df.shape}\")\n",
        "\n",
        "        # Feature Selection\n",
        "        print(f\"\\nSTEP 2: FEATURE SELECTION\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Define features based on available columns\n",
        "        available_features = []\n",
        "        target_column = 'Salary'\n",
        "\n",
        "        # Check which features are available in the dataset\n",
        "        feature_mapping = {\n",
        "            'Age': 'Age',\n",
        "            'Years of Experience': 'Years of Experience',\n",
        "            'Gender': 'Gender',\n",
        "            'Education Level': 'Education Level',\n",
        "            'Job Title': 'Job Title'\n",
        "        }\n",
        "\n",
        "        for feature_name, column_name in feature_mapping.items():\n",
        "            if column_name in df.columns:\n",
        "                available_features.append(column_name)\n",
        "                print(f\"‚úì Using feature: {column_name}\")\n",
        "            else:\n",
        "                print(f\"‚úó Feature not available: {column_name}\")\n",
        "\n",
        "        # Prepare feature matrix X and target vector y\n",
        "        X = df[available_features].copy()\n",
        "        y = df[target_column].copy()\n",
        "\n",
        "        print(f\"\\nSelected features: {available_features}\")\n",
        "        print(f\"Target variable: {target_column}\")\n",
        "        print(f\"Feature matrix shape: {X.shape}\")\n",
        "        print(f\"Target vector shape: {y.shape}\")\n",
        "\n",
        "        return X, y, df\n",
        "\n",
        "    def encode_categorical_features(self, X):\n",
        "        \"\"\"\n",
        "        Encode categorical features using One-Hot Encoding\n",
        "        \"\"\"\n",
        "        print(f\"\\nSTEP 3: ENCODING CATEGORICAL FEATURES\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Identify categorical and numerical columns\n",
        "        categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
        "        numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "        print(f\"Categorical columns: {categorical_columns}\")\n",
        "        print(f\"Numerical columns: {numerical_columns}\")\n",
        "\n",
        "        # Create preprocessor\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', StandardScaler(), numerical_columns),\n",
        "                ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_columns)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.preprocessor = preprocessor\n",
        "        self.feature_columns = {\n",
        "            'numerical': numerical_columns,\n",
        "            'categorical': categorical_columns\n",
        "        }\n",
        "\n",
        "        return preprocessor\n",
        "\n",
        "    def split_data(self, X, y, test_size=0.2, random_state=42):\n",
        "        \"\"\"\n",
        "        Split the data into training and testing sets\n",
        "        \"\"\"\n",
        "        print(f\"\\nSTEP 4: SPLITTING THE DATA\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "        print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "        print(f\"Training set percentage: {(1-test_size)*100:.1f}%\")\n",
        "        print(f\"Testing set percentage: {test_size*100:.1f}%\")\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def create_ensemble_models(self):\n",
        "        \"\"\"\n",
        "        Create ensemble learning models\n",
        "        \"\"\"\n",
        "        print(f\"\\nSTEP 5: CREATING ENSEMBLE MODELS\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Random Forest Regressor\n",
        "        rf_model = RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            random_state=42,\n",
        "            max_depth=10,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2\n",
        "        )\n",
        "\n",
        "        # Gradient Boosting Regressor\n",
        "        gb_model = GradientBoostingRegressor(\n",
        "            n_estimators=100,\n",
        "            random_state=42,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2\n",
        "        )\n",
        "\n",
        "        # Voting Regressor (combines RF and GB)\n",
        "        voting_model = VotingRegressor(\n",
        "            estimators=[\n",
        "                ('random_forest', rf_model),\n",
        "                ('gradient_boosting', gb_model)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        models = {\n",
        "            'Random Forest': rf_model,\n",
        "            'Gradient Boosting': gb_model,\n",
        "            'Voting Regressor': voting_model\n",
        "        }\n",
        "\n",
        "        print(\"Created ensemble models:\")\n",
        "        for name in models.keys():\n",
        "            print(f\"‚úì {name}\")\n",
        "\n",
        "        return models\n",
        "\n",
        "    def train_and_evaluate_models(self, models, X_train, X_test, y_train, y_test):\n",
        "        \"\"\"\n",
        "        Train and evaluate all models\n",
        "        \"\"\"\n",
        "        print(f\"\\nSTEP 6: TRAINING AND EVALUATING MODELS\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Fit the preprocessor and transform the data\n",
        "        X_train_processed = self.preprocessor.fit_transform(X_train)\n",
        "        X_test_processed = self.preprocessor.transform(X_test)\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for name, model in models.items():\n",
        "            print(f\"\\nTraining {name}...\")\n",
        "\n",
        "            # Train the model\n",
        "            model.fit(X_train_processed, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_train_pred = model.predict(X_train_processed)\n",
        "            y_test_pred = model.predict(X_test_processed)\n",
        "\n",
        "            # Calculate metrics\n",
        "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "            train_r2 = r2_score(y_train, y_train_pred)\n",
        "            test_r2 = r2_score(y_test, y_test_pred)\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "            # Store results\n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'train_mae': train_mae,\n",
        "                'test_mae': test_mae,\n",
        "                'train_r2': train_r2,\n",
        "                'test_r2': test_r2,\n",
        "                'train_rmse': train_rmse,\n",
        "                'test_rmse': test_rmse\n",
        "            }\n",
        "\n",
        "            # Print results\n",
        "            print(f\"{name} Results:\")\n",
        "            print(f\"  Training MAE: ${train_mae:,.2f}\")\n",
        "            print(f\"  Testing MAE:  ${test_mae:,.2f}\")\n",
        "            print(f\"  Training R¬≤:  {train_r2:.4f}\")\n",
        "            print(f\"  Testing R¬≤:   {test_r2:.4f}\")\n",
        "            print(f\"  Training RMSE: ${train_rmse:,.2f}\")\n",
        "            print(f\"  Testing RMSE:  ${test_rmse:,.2f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def find_best_model(self, results):\n",
        "        \"\"\"\n",
        "        Find the best performing model based on test R¬≤ score\n",
        "        \"\"\"\n",
        "        print(f\"\\nSTEP 7: MODEL COMPARISON\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Create comparison dataframe\n",
        "        comparison_data = []\n",
        "        for name, metrics in results.items():\n",
        "            comparison_data.append({\n",
        "                'Model': name,\n",
        "                'Test MAE': f\"${metrics['test_mae']:,.2f}\",\n",
        "                'Test R¬≤': f\"{metrics['test_r2']:.4f}\",\n",
        "                'Test RMSE': f\"${metrics['test_rmse']:,.2f}\"\n",
        "            })\n",
        "\n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        print(\"Model Performance Comparison:\")\n",
        "        print(comparison_df.to_string(index=False))\n",
        "\n",
        "        # Find best model based on test R¬≤ score\n",
        "        best_model_name = max(results.keys(), key=lambda k: results[k]['test_r2'])\n",
        "        best_model = results[best_model_name]['model']\n",
        "\n",
        "        print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
        "        print(f\"   Test R¬≤ Score: {results[best_model_name]['test_r2']:.4f}\")\n",
        "        print(f\"   Test MAE: ${results[best_model_name]['test_mae']:,.2f}\")\n",
        "\n",
        "        return best_model_name, best_model\n",
        "\n",
        "    def save_model(self, model, model_name, filename=None):\n",
        "        \"\"\"\n",
        "        Save the trained model and preprocessor to files\n",
        "        \"\"\"\n",
        "        print(f\"\\nSTEP 8: SAVING THE MODEL\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        if filename is None:\n",
        "            filename = f\"best_salary_model_{model_name.lower().replace(' ', '_')}\"\n",
        "\n",
        "        # Save the model\n",
        "        model_path = f\"{filename}.pkl\"\n",
        "        joblib.dump(model, model_path)\n",
        "        print(f\"‚úì Model saved as: {model_path}\")\n",
        "\n",
        "        # Save the preprocessor\n",
        "        preprocessor_path = f\"{filename}_preprocessor.pkl\"\n",
        "        joblib.dump(self.preprocessor, preprocessor_path)\n",
        "        print(f\"‚úì Preprocessor saved as: {preprocessor_path}\")\n",
        "\n",
        "        # Save feature information\n",
        "        feature_info = {\n",
        "            'feature_columns': self.feature_columns,\n",
        "            'model_name': model_name\n",
        "        }\n",
        "        feature_path = f\"{filename}_features.pkl\"\n",
        "        joblib.dump(feature_info, feature_path)\n",
        "        print(f\"‚úì Feature info saved as: {feature_path}\")\n",
        "\n",
        "        return model_path, preprocessor_path, feature_path\n",
        "\n",
        "    def load_model(self, model_path, preprocessor_path, feature_path):\n",
        "        \"\"\"\n",
        "        Load a saved model for making predictions\n",
        "        \"\"\"\n",
        "        self.model = joblib.load(model_path)\n",
        "        self.preprocessor = joblib.load(preprocessor_path)\n",
        "        feature_info = joblib.load(feature_path)\n",
        "        self.feature_columns = feature_info['feature_columns']\n",
        "\n",
        "        print(f\"Model loaded successfully!\")\n",
        "        return True\n",
        "\n",
        "    def predict_salary(self, input_data):\n",
        "        \"\"\"\n",
        "        Make salary predictions for new data\n",
        "        \"\"\"\n",
        "        if self.model is None or self.preprocessor is None:\n",
        "            raise ValueError(\"Model not loaded. Please load a trained model first.\")\n",
        "\n",
        "        # Preprocess the input data\n",
        "        input_processed = self.preprocessor.transform(input_data)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = self.model.predict(input_processed)\n",
        "\n",
        "        return prediction\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the complete salary prediction pipeline\n",
        "    \"\"\"\n",
        "    print(\"SALARY PREDICTION WITH ENSEMBLE LEARNING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize the predictor\n",
        "    predictor = SalaryPredictor()\n",
        "\n",
        "    # Step 1: Load and prepare data\n",
        "    X, y, df = predictor.load_and_prepare_data()\n",
        "\n",
        "    # Step 2: Encode categorical features\n",
        "    preprocessor = predictor.encode_categorical_features(X)\n",
        "\n",
        "    # Step 3: Split the data\n",
        "    X_train, X_test, y_train, y_test = predictor.split_data(X, y)\n",
        "\n",
        "    # Step 4: Create ensemble models\n",
        "    models = predictor.create_ensemble_models()\n",
        "\n",
        "    # Step 5: Train and evaluate models\n",
        "    results = predictor.train_and_evaluate_models(models, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Step 6: Find best model\n",
        "    best_model_name, best_model = predictor.find_best_model(results)\n",
        "\n",
        "    # Step 7: Save the best model\n",
        "    predictor.model = best_model\n",
        "    model_paths = predictor.save_model(best_model, best_model_name)\n",
        "\n",
        "    print(f\"\\nüéâ SALARY PREDICTION MODEL TRAINING COMPLETED!\")\n",
        "    print(f\"Best model ({best_model_name}) has been saved and is ready for predictions.\")\n",
        "\n",
        "    # Demonstrate prediction on a sample\n",
        "    print(f\"\\nSTEP 9: SAMPLE PREDICTION\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Create a sample prediction\n",
        "    sample_data = X.iloc[:1].copy()  # Take first row as sample\n",
        "    prediction = predictor.predict_salary(sample_data)\n",
        "    actual_salary = y.iloc[0]\n",
        "\n",
        "    print(f\"Sample Input Data:\")\n",
        "    for col in sample_data.columns:\n",
        "        print(f\"  {col}: {sample_data.iloc[0][col]}\")\n",
        "\n",
        "    print(f\"\\nPredicted Salary: ${prediction[0]:,.2f}\")\n",
        "    print(f\"Actual Salary: ${actual_salary:,.2f}\")\n",
        "    print(f\"Prediction Error: ${abs(prediction[0] - actual_salary):,.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}